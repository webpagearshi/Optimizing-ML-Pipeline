# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**Problem Statement:** We will analyse the bank marketing dataset and train it to determine whether a customer will make a term deposit or not. We can determine the features which influence the outcome so that in our next marketing campaign we can identify the target customers who have a higher probability of converting and making a term deposit. The label "y" tells us whether a customer is subscribed to a term deposit or not and this is the target column for predictions.

**Solution:** The best performing model was a logisitc regression model with hyper parameters '--C' = '1' and '--max-iter' = '120' with an accuracy of 0.9121396054628225.

## Scikit-learn Pipeline 
**Pipeline Architecture:** We first created a compute instance to spin up a virtual machine and provision correct resources for that virtual machine. Once a compute instance is created we used it to launch a jupyter notebook which is used to access the existing workspace, create an experiment and a compute cluster(or find an existing one).

**Data:** We created a Tabular Dataset from a delimited file behind a public web url. Next we have used the clean data function to clean our data. Since machine learning models accept only numerical data we will convert months and weekdays into numbers, and one hot encode non numeric features.

**Hyperparameters:** The hyper parameters which are tuned in this model are C (which is inverse of regularization strength) and max-iter.

**Algorithm:** Our classification algorithm is Logistic Regression

**What are the benefits of the parameter sampler you chose?**

We have used Random Parameter sampling as it supports both discrete and continuous parameters and also early termination of low performance runs. In Random Sampling hyper parameter values are chosen randomly from the defined limits.

**What are the benefits of the early stopping policy you chose?**

The early stopping policy chosen for this ML Pipeline Bandit Policy and the reason for choosing this is that the comparsion is based on best performing run hence runs which have a huge difference from the best performing training run are terminated. Slack factor or slack amount defines the allowable slack in primary metric.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

The best performing model generated by AutoML was Voting Ensemble and the hyperparameters generated by AutoML model are: min_samples_leaf=0.01,min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,  flatten_transform=None,  verbose=0 and weights=[0.26666666666666666,0.3333333333333333,0.06666666666666667,0.06666666666666667,0.06666666666666667,0.06666666666666667,0.13333333333333333]

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

The accuracy for logistic regression was 0.9121396054628225 and the accuracy for Voting Ensemble was 0.91586. Logistic regression is a single model and voting ensemble is an ensemble model(i.e., it has a number of models in it) hence it has lower error and less overfitting.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
In future experiments for azure ml using Python SDK I would like to try out other scikit-learn models for classification and see if we can improve the accuracy. For autoML I will retrieve the top features from the model explanation and then reduce the number of features by using the top features. I would also like to experiment with number of cross validations(CV) and see if reducing the number affects the accuracy.This is because higher value of CV results in longer training time and thus increases cost. On the other hand very small values of CV will lead to over-fitting. I would also like to explore how to deal with class-imbalance issue.

## Proof of cluster clean up
Compute cluster was deleted.

##Resources: Udacity course material and Microsoft Docs.

```

```
